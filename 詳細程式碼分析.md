# 詳細程式碼分析 - 各服務技術細節 🔍

## 🎤 ASR 服務深度解析

### 核心技術棧
```python
# AI/ML 相關
import torch                    # PyTorch 深度學習框架
import torchaudio              # PyTorch 音訊處理
from transformers import (     # Hugging Face 模型庫
    AutoModelForSpeechSeq2Seq,
    AutoProcessor, 
    pipeline
)
import numpy as np             # 數值計算

# Web 服務
from fastapi import FastAPI, File, UploadFile
```

### 模型載入機制
```python
class ASRService:
    def _load_model(self):
        # 1. 載入預訓練模型
        self.model = AutoModelForSpeechSeq2Seq.from_pretrained(
            self.model_name_or_path,
            torch_dtype=self.torch_dtype,    # 使用半精度浮點數節省記憶體
            low_cpu_mem_usage=True,          # 降低 CPU 記憶體使用
            use_safetensors=True             # 使用安全的張量格式
        )
        
        # 2. 載入音訊處理器
        self.processor = AutoProcessor.from_pretrained(self.model_name_or_path)
        
        # 3. 建立推理管道
        self.pipe = pipeline(
            "automatic-speech-recognition",
            model=self.model,
            tokenizer=self.processor.tokenizer,
            feature_extractor=self.processor.feature_extractor,
            max_new_tokens=128,              # 最大生成 token 數
            chunk_length_s=30,              # 音訊分塊長度
            batch_size=16,                  # 批次大小
            return_timestamps=True,         # 返回時間戳
            torch_dtype=self.torch_dtype,
            device=self.device,
        )
```

**學習重點**:
- **記憶體優化**: `low_cpu_mem_usage=True` 減少載入時的記憶體峰值
- **精度控制**: 使用 `torch.float16` 在 GPU 上節省記憶體
- **分塊處理**: `chunk_length_s=30` 將長音訊分成小塊處理

### 音訊預處理流程
```python
def preprocess_audio(self, audio_bytes: bytes) -> np.ndarray:
    # 1. 從位元組流讀取音訊
    audio_io = io.BytesIO(audio_bytes)
    
    # 2. 使用 torchaudio 載入
    waveform, sample_rate = torchaudio.load(audio_io, format="m4a")
    
    # 3. 轉換為單聲道
    if waveform.shape[0] > 1:
        waveform = torch.mean(waveform, dim=0, keepdim=True)
    
    # 4. 重新取樣到 16kHz (模型要求)
    if sample_rate != 16000:
        resampler = torchaudio.transforms.Resample(sample_rate, 16000)
        waveform = resampler(waveform)
    
    # 5. 轉換為 numpy 陣列
    return waveform.squeeze().numpy()
```

**學習重點**:
- **格式轉換**: LINE 傳送的是 M4A 格式，需要轉換
- **聲道處理**: 將立體聲轉為單聲道
- **取樣率標準化**: ASR 模型通常要求 16kHz

---

## 🔊 TTS 服務深度解析

### 多引擎架構設計
```python
class TTSService:
    def __init__(self):
        # 檢查可用的 TTS 引擎
        self.available_engines = []
        
        if EDGE_TTS_AVAILABLE:
            self.available_engines.append("edge")
        if GTTS_AVAILABLE:
            self.available_engines.append("gtts")
        if PYTTSX3_AVAILABLE:
            self.available_engines.append("pyttsx3")
        
        # 設定預設引擎
        self.tts_engine = os.getenv("TTS_ENGINE", "edge").lower()
        
        logger.info(f"可用的 TTS 引擎: {self.available_engines}")
        logger.info(f"當前使用引擎: {self.tts_engine}")
```

### Edge TTS 實作 (推薦)
```python
async def synthesize_with_edge_tts(self, text: str, voice: str) -> bytes:
    try:
        # 1. 建立 Edge TTS 通訊物件
        communicate = edge_tts.Communicate(text, voice)
        
        # 2. 串流生成音訊資料
        audio_data = b""
        async for chunk in communicate.stream():
            if chunk["type"] == "audio":
                audio_data += chunk["data"]
        
        return audio_data
        
    except Exception as e:
        logger.error(f"Edge TTS 合成失敗: {e}")
        raise HTTPException(status_code=500, detail=f"語音合成失敗: {str(e)}")
```

**學習重點**:
- **串流處理**: `async for` 處理音訊資料流
- **異常處理**: 提供明確的錯誤訊息
- **免費服務**: Edge TTS 是微軟提供的免費服務

### Google TTS 實作 (備用)
```python
async def synthesize_with_gtts(self, text: str, lang: str = "zh-tw") -> bytes:
    try:
        # 1. 建立 gTTS 物件
        tts = gTTS(text=text, lang=lang, slow=False)
        
        # 2. 儲存到記憶體緩衝區
        audio_buffer = io.BytesIO()
        tts.write_to_fp(audio_buffer)
        audio_buffer.seek(0)
        
        return audio_buffer.read()
        
    except Exception as e:
        logger.error(f"Google TTS 合成失敗: {e}")
        raise HTTPException(status_code=500, detail=f"語音合成失敗: {str(e)}")
```

**學習重點**:
- **記憶體緩衝**: 使用 `io.BytesIO()` 避免建立臨時檔案
- **語言支援**: 支援多種語言代碼

---

## 🧠 記憶服務深度解析

### 資料結構設計思路
```python
@dataclass
class ChatMessage:
    role: str           # "user" 或 "assistant"
    content: str        # 訊息內容
    timestamp: datetime # 精確的時間戳記
    message_type: str   # "text", "voice", "image" 等

    def to_dict(self) -> dict:
        """序列化為字典格式"""
        data = asdict(self)
        data["timestamp"] = self.timestamp.isoformat()  # ISO 格式時間
        return data

    @classmethod
    def from_dict(cls, data: dict) -> "ChatMessage":
        """從字典反序列化"""
        data["timestamp"] = datetime.fromisoformat(data["timestamp"])
        return cls(**data)
```

**學習重點**:
- **資料類別**: `@dataclass` 自動生成 `__init__`, `__repr__` 等方法
- **序列化**: 提供 JSON 轉換方法
- **時間處理**: 使用 ISO 格式確保跨平台相容性

### 執行緒安全的檔案操作
```python
class JSONMemoryBackend:
    def __init__(self, data_dir: str):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(parents=True, exist_ok=True)
        self.lock = threading.Lock()  # 執行緒鎖

    def save_user_memory(self, user_memory: UserMemory):
        """執行緒安全的儲存操作"""
        with self.lock:  # 確保同時只有一個執行緒寫入
            file_path = self.data_dir / f"{user_memory.user_id}.json"
            
            # 原子性寫入：先寫入臨時檔案，再重新命名
            temp_file = file_path.with_suffix('.tmp')
            
            try:
                with open(temp_file, 'w', encoding='utf-8') as f:
                    json.dump(user_memory.to_dict(), f, 
                             ensure_ascii=False, indent=2)
                
                # 原子性重新命名
                temp_file.replace(file_path)
                
            except Exception as e:
                # 清理臨時檔案
                if temp_file.exists():
                    temp_file.unlink()
                raise e
```

**學習重點**:
- **執行緒安全**: `threading.Lock()` 防止資料競爭
- **原子性操作**: 先寫臨時檔案再重新命名，避免資料損壞
- **錯誤處理**: 失敗時清理臨時檔案

### 記憶管理邏輯
```python
class MemoryManager:
    def add_message(self, user_id: str, role: str, content: str, message_type: str = "text"):
        """新增訊息並管理記憶限制"""
        # 1. 載入用戶記憶
        user_memory = self.backend.load_user_memory(user_id)
        
        # 2. 建立新訊息
        new_message = ChatMessage(
            role=role,
            content=content,
            timestamp=datetime.now(),
            message_type=message_type
        )
        
        # 3. 新增到記憶中
        user_memory.messages.append(new_message)
        user_memory.total_messages += 1
        user_memory.last_interaction = datetime.now()
        
        # 4. 記憶限制管理
        if len(user_memory.messages) > self.max_messages_per_user:
            # 保留最近的訊息，刪除舊的
            user_memory.messages = user_memory.messages[-self.max_messages_per_user:]
        
        # 5. 儲存更新後的記憶
        self.backend.save_user_memory(user_memory)
```

**學習重點**:
- **記憶限制**: 防止記憶體無限增長
- **時間戳記**: 追蹤用戶活動
- **資料一致性**: 確保所有相關欄位都更新

### 對話上下文生成
```python
def get_conversation_context(self, user_id: str) -> List[Dict]:
    """生成 OpenAI API 格式的對話上下文"""
    user_memory = self.backend.load_user_memory(user_id)
    
    # 1. 取得最近的對話
    recent_messages = user_memory.messages[-self.max_context_messages:]
    
    # 2. 轉換為 OpenAI 格式
    context = []
    
    # 3. 添加系統提示 (包含用戶偏好)
    system_prompt = self._generate_system_prompt(user_memory.preferences)
    context.append({"role": "system", "content": system_prompt})
    
    # 4. 添加對話歷史
    for message in recent_messages:
        context.append({
            "role": message.role,
            "content": message.content
        })
    
    return context

def _generate_system_prompt(self, preferences: Dict[str, str]) -> str:
    """根據用戶偏好生成系統提示"""
    base_prompt = "你是一個友善且有用的 AI 助手。"
    
    # 根據語言偏好調整語調
    if preferences.get("language") == "formal":
        base_prompt += "請使用正式、禮貌的語調回應。"
    elif preferences.get("language") == "casual":
        base_prompt += "請使用輕鬆、親切的語調回應。"
    
    return base_prompt
```

**學習重點**:
- **上下文管理**: 只傳送最近的對話避免 token 超限
- **個人化**: 根據用戶偏好調整 AI 行為
- **系統提示**: 使用系統角色設定 AI 的行為模式

---

## 🌐 LINE Bot 主服務深度解析

### 異步事件處理架構
```python
class LineBotService:
    def _register_handlers(self):
        """註冊 LINE Bot 事件處理器"""
        
        @self.handler.add(MessageEvent, message=AudioMessageContent)
        def handle_audio_message(event):
            # 使用異步任務避免阻塞
            asyncio.create_task(self.process_audio_message(event))

        @self.handler.add(MessageEvent, message=TextMessageContent)
        def handle_text_message(event):
            asyncio.create_task(self.process_text_message(event))
```

**學習重點**:
- **裝飾器模式**: `@self.handler.add()` 註冊事件處理器
- **異步任務**: `asyncio.create_task()` 避免阻塞主執行緒
- **事件驅動**: 基於事件的程式設計模式

### 微服務通訊模式
```python
async def transcribe_audio(self, audio_content: bytes) -> Optional[str]:
    """呼叫 ASR 服務進行語音辨識"""
    try:
        async with aiohttp.ClientSession() as session:
            # 1. 準備檔案上傳
            with tempfile.NamedTemporaryFile(suffix=".m4a", delete=False) as temp_file:
                temp_file.write(audio_content)
                temp_file_path = temp_file.name

            # 2. 建立表單資料
            with open(temp_file_path, "rb") as f:
                data = aiohttp.FormData()
                data.add_field(
                    "audio_file",
                    f,
                    filename="audio.m4a",
                    content_type="audio/x-m4a",
                )

                # 3. 發送 HTTP 請求
                async with session.post(
                    f"{self.asr_service_url}/recognize",
                    data=data,
                    timeout=aiohttp.ClientTimeout(total=120),  # 2 分鐘超時
                ) as response:
                    if response.status == 200:
                        result = await response.json()
                        return result.get("transcription", "")
                    else:
                        logger.error(f"ASR 服務錯誤: {response.status}")
                        return None

    except Exception as e:
        logger.error(f"語音辨識失敗: {str(e)}")
        return None
    finally:
        # 4. 清理臨時檔案
        if "temp_file_path" in locals() and Path(temp_file_path).exists():
            Path(temp_file_path).unlink()
```

**學習重點**:
- **資源管理**: 使用 `async with` 確保連線正確關閉
- **檔案上傳**: 使用 `FormData` 上傳二進制檔案
- **超時控制**: 設定合理的超時時間
- **清理機制**: 確保臨時檔案被刪除

### OpenAI API 整合 (含記憶)
```python
async def get_openai_response_with_context(
    self, context_messages: list, current_message: str
) -> Optional[str]:
    """使用 OpenAI API 與對話上下文生成回應"""
    try:
        # 1. 準備訊息列表
        messages = context_messages.copy()

        # 2. 確保有系統訊息
        if not messages or messages[0]["role"] != "system":
            messages.insert(0, {
                "role": "system",
                "content": "你是一個友善且有用的 AI 助手。你能夠記住我們之前的對話內容，並提供連貫的回應。",
            })

        # 3. 添加當前用戶訊息
        messages.append({"role": "user", "content": current_message})

        # 4. 呼叫 OpenAI API
        from openai import AsyncOpenAI
        
        client = AsyncOpenAI(api_key=self.openai_api_key)
        
        response = await client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages,
            max_tokens=500,
            temperature=0.7,
        )

        assistant_message = response.choices[0].message.content.strip()
        logger.info(f"🤖 OpenAI 回應 (含記憶): {assistant_message[:50]}...")
        return assistant_message

    except Exception as e:
        logger.error(f"🤖 OpenAI API 錯誤 (含記憶): {e}")
        return self.generate_smart_fallback(current_message)
```

**學習重點**:
- **上下文管理**: 將對話歷史傳給 OpenAI
- **錯誤降級**: API 失敗時使用後備回應
- **參數調整**: `temperature=0.7` 控制回應的創造性

### 智能後備機制
```python
def generate_smart_fallback(self, text: str) -> str:
    """智能後備回應系統"""
    text_lower = text.lower()

    # 關鍵字匹配模式
    patterns = {
        "greeting": ["你好", "哈囉", "hello", "hi", "嗨"],
        "question": ["什麼", "怎麼", "如何", "為什麼", "哪裡"],
        "health": ["健康", "醫療", "生病", "症狀", "藥物"],
        "time": ["時間", "現在", "幾點"],
        "thanks": ["謝謝", "感謝", "thanks", "thank you"],
    }

    # 根據匹配結果生成回應
    for category, keywords in patterns.items():
        if any(word in text_lower for word in keywords):
            return self._generate_response_by_category(category, text)
    
    # 預設回應
    return f"收到您的訊息「{text}」。我是 AI 智能助手，目前正在學習中。"

def _generate_response_by_category(self, category: str, text: str) -> str:
    """根據分類生成對應回應"""
    responses = {
        "greeting": "你好！我是語音智能助手，很高興為您服務！",
        "question": f"關於「{text}」這個問題，我建議您可以查詢相關資料或諮詢專家。",
        "health": "關於健康問題，我建議諮詢專業醫師。如果有緊急狀況，請立即就醫！",
        "time": f"現在時間是 {datetime.now().strftime('%Y年%m月%d日 %H:%M')}。",
        "thanks": "不客氣！很高興能幫助您。如果還有其他問題，隨時歡迎詢問！",
    }
    
    return responses.get(category, "感謝您的訊息，我會盡力協助您。")
```

**學習重點**:
- **關鍵字匹配**: 使用簡單的規則匹配使用者意圖
- **分類回應**: 根據不同類別提供適當回應
- **降級策略**: 確保系統永遠有回應能力

---

## 🔄 完整的資料流程追蹤

### 語音訊息處理流程
```python
async def process_audio_message(self, event):
    """完整的語音處理流程"""
    user_id = event.source.user_id
    
    try:
        # 步驟 1: 下載語音 (LINE API)
        logger.info(f"🔽 開始下載語音: {event.message.id}")
        audio_content = await self.download_audio_content(event.message.id)
        
        # 步驟 2: 語音辨識 (ASR 服務)
        logger.info(f"🎯 開始語音辨識，檔案大小: {len(audio_content)} 位元組")
        recognized_text = await self.transcribe_audio(audio_content)
        
        # 步驟 3: 記憶管理 (記憶服務)
        logger.info(f"🧠 將用戶語音加入記憶: {recognized_text}")
        await self.add_message_to_memory(user_id, "user", recognized_text, "voice")
        
        # 步驟 4: 獲取 AI 回應 (OpenAI API + 記憶服務)
        logger.info(f"🤖 生成 AI 回應 (含對話歷史)")
        llm_response = await self.get_llm_response_with_memory(user_id, recognized_text)
        
        # 步驟 5: 儲存 AI 回應 (記憶服務)
        logger.info(f"🧠 將 AI 回應加入記憶")
        await self.add_message_to_memory(user_id, "assistant", llm_response, "voice")
        
        # 步驟 6: 語音合成 (TTS 服務)
        logger.info(f"🔊 開始語音合成")
        audio_file_path = await self.synthesize_speech(llm_response)
        
        # 步驟 7: 回覆用戶 (LINE API)
        if audio_file_path:
            logger.info(f"📤 回覆語音訊息")
            await self.reply_audio(event.reply_token, audio_file_path)
        else:
            logger.info(f"📤 回覆文字訊息 (語音合成失敗)")
            await self.reply_text(event.reply_token, llm_response)
            
    except Exception as e:
        logger.error(f"❌ 語音處理失敗: {str(e)}")
        await self.reply_text(event.reply_token, "抱歉，語音處理過程中發生錯誤。")
```

**學習重點**:
- **詳細日誌**: 每個步驟都有清楚的日誌記錄
- **錯誤恢復**: 語音合成失敗時改用文字回覆
- **資源清理**: 確保臨時檔案被正確清理

---

## 📊 效能優化技巧

### 1. 記憶體管理
```python
# ASR 服務中的記憶體優化
self.model = AutoModelForSpeechSeq2Seq.from_pretrained(
    model_name,
    torch_dtype=torch.float16,      # 半精度浮點數
    low_cpu_mem_usage=True,         # 減少 CPU 記憶體使用
    device_map="auto"               # 自動設備映射
)
```

### 2. 連線池管理
```python
# 使用連線池提升效能
async with aiohttp.ClientSession(
    connector=aiohttp.TCPConnector(limit=100),  # 連線池大小
    timeout=aiohttp.ClientTimeout(total=30)     # 統一超時設定
) as session:
    # HTTP 請求
```

### 3. 快取機制
```python
from functools import lru_cache

@lru_cache(maxsize=128)
def get_user_preferences(user_id: str) -> Dict[str, str]:
    """快取用戶偏好設定"""
    # 減少重複的檔案讀取
    return self.backend.load_user_memory(user_id).preferences
```

---

## 🎓 學習總結

### 核心技術概念

1. **微服務架構**: 將複雜系統分解為獨立的小服務
2. **異步程式設計**: 使用 `async/await` 處理 I/O 密集操作
3. **RESTful API**: 標準化的服務間通訊協定
4. **錯誤處理**: 多層次的錯誤處理和降級機制
5. **資源管理**: 正確的檔案和連線資源管理

### 實用程式設計模式

1. **工廠模式**: TTS 服務的多引擎選擇
2. **裝飾器模式**: LINE Bot 的事件處理器註冊
3. **策略模式**: 不同情況下的回應策略
4. **觀察者模式**: 事件驅動的架構設計

### 最佳實踐

1. **日誌記錄**: 詳細的操作日誌便於除錯
2. **配置管理**: 使用環境變數管理設定
3. **錯誤處理**: 永遠有備案和降級機制
4. **資源清理**: 確保臨時資源被正確釋放
5. **型別提示**: 使用型別提示增加程式碼可讀性

這個專案展示了現代 Python 開發的許多重要概念，是學習後端開發和 AI 應用整合的絕佳範例！ 🚀 